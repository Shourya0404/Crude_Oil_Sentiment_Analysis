{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model will be used to predict the sentiment for news articles on Crude Oil\n",
    "### A Gaussian Naive Bayes classifier has been used\n",
    "### The process will be divided into 3 phases: \n",
    "### 1. Obtaining data from OilPrice.com\n",
    "### 2. Training the model using 90% of this data by using the vaderSentiment NLP library\n",
    "### The library will be used to predict whether the article sentiment is positive or negative.\n",
    "### 3. Testing the model by using the remaining 10% of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\samsung\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n"
     ]
    }
   ],
   "source": [
    "#Install vaderSentiment, a popular NLP library developed by Georgia Tech\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required libraries successfully installed\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "print(\"Required libraries successfully installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store scraped news urls, headlines and text\n",
    "url_list = []\n",
    "news_text = []\n",
    "headlines = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 140 articles obtained\n"
     ]
    }
   ],
   "source": [
    "# Get the url's for all articles which will be used to create the training dataset\n",
    "\n",
    "for i in range(1,8): #parameters of range function correspond to page numbers in the website with news listings\n",
    "    #get the list of unique urls in the page\n",
    "    url = 'https://oilprice.com/Energy/Crude-Oil/Page-{}.html'.format(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, \"html.parser\")\n",
    "    for links in soup.find_all('div', {'class': 'categoryArticle'}):\n",
    "        for info in links.find_all('a'):\n",
    "            if info.get('href') not in url_list: # Avoid repeats\n",
    "                url_list.append(info.get('href'))\n",
    "print(\"A total of\",len(url_list),\"articles obtained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from within each article and store into lists \n",
    "# The headline of the article along with the text within the article will be scraped\n",
    "\n",
    "for www in url_list:\n",
    "    #access each url\n",
    "    headlines.append(www.split(\"/\")[-1].replace('-',' '))\n",
    "    request = requests.get(www)\n",
    "    soup = BeautifulSoup(request.text, \"html.parser\")\n",
    "    \n",
    "    #store the text of the news\n",
    "    temp_news = []\n",
    "    for news in soup.find_all('p'):\n",
    "            temp_news.append(news.text)\n",
    "            \n",
    "    # We don't need the author name which is given at the end of each article \n",
    "    # We find where this is located and trim our temp_news list \n",
    "    #find the last line of the news article we need \n",
    "    for last_sentence in reversed(temp_news):\n",
    "        if last_sentence.split(\" \")[0]==\"By\" and last_sentence.split(\" \")[-1]==\"Oilprice.com\":\n",
    "            break\n",
    "        elif last_sentence.split(\" \")[0]==\"By\":\n",
    "            break\n",
    "            \n",
    "    temp_news=temp_news[temp_news.index(\"More Info\")+1:temp_news.index(last_sentence)]\n",
    "    news_article_joined=' '.join(temp_news)\n",
    "    news_text.append(news_article_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save news text along with the news headline in a dataframe      \n",
    "news_df = pd.DataFrame({ 'Headline': headlines,\n",
    "                         'News': news_text,\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use VADER to perform sentiment analysis on stored news articles\n",
    "news_sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "def comp_score(text):\n",
    "   return news_sentiment.polarity_scores(text)[\"compound\"]   \n",
    "  \n",
    "news_df[\"sentiment\"] = news_df[\"News\"].apply(comp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying the sentiment score into positive, negative, or neutral\n",
    "news_df.loc[news_df['sentiment'] >=0.1, 'Sentiment_Classification'] = 'positive'\n",
    "news_df.loc[news_df['sentiment']<=-0.1,'Sentiment_Classification']= 'negative'\n",
    "news_df['Sentiment_Classification']=news_df['Sentiment_Classification'].fillna('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the dataset that will be used for the prediction model\n",
    "news_df.head()\n",
    "news_df.to_csv(\"CrudeOil_News_Articles.csv\",index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step is the vectorization of data\n",
    "### The news articles will be used for this\n",
    "### All stop words will be dropped\n",
    "### The pickle library will be used to store vectorized model for reuse in future\n",
    "### Term feature- Inverse Document feature method will be used to extract important features from the document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the CSV file\n",
    "data=pd.read_csv(\"CrudeOil_News_Articles.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the articles did not return any data, we need to drop these columns before we vectorize the data\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#We need the news article text data, which is located in column 1\n",
    "news_data=data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a vectorize object \n",
    "vectorize_object = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_vec = vectorize_object.fit_transform(news_data)\n",
    "pickle.dump(vectorize_object, open(\"crude_oil_data_vectorize\", 'wb')) # Save vectorizer for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert sparse matrix into dense matrix\n",
    "news_data_vec = news_data_vec.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data by applying term frequency inverse document frequency (TF-IDF) \n",
    "# This is important because we do not want the model to consider very frequently occurring words \n",
    "# (for e.g. oil) which do not affect the sentiment but occur frequently because they are subjects \n",
    "# By using TF-IDF, we reduce the weighting of these words\n",
    "# We then normalize the data so that vector values are between -1 and 1\n",
    "tfi = TfidfTransformer() \n",
    "news_data_tfi = tfi.fit_transform(news_data_vec)\n",
    "news_data_tfi = news_data_tfi.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the tfi vector with the data vector\n",
    "news_data_tfi_df=pd.DataFrame(news_data_tfi)\n",
    "news_data_tfi_df=news_data_tfi_df.join(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the data vector is ready, we can split it into train and test \n",
    "### For this case, a 9:1 split is taken, i.e. 90% of the data is used for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(news_data_tfi_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.iloc[:,0:7603]\n",
    "y_train=train.iloc[:,-1]\n",
    "\n",
    "# Train the NB classifier\n",
    "classifier = GaussianNB().fit(x_train, y_train) \n",
    "pickle.dump(classifier, open(\"nb_clf_crude_oil\", 'wb')) # Save the classifier model for reuse in future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test.iloc[:,0:7603]\n",
    "y_test=test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make a sentiment prediciton \n",
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment_Classification\n",
       "0                  positive\n",
       "1                  negative\n",
       "2                  positive\n",
       "3                  positive\n",
       "4                  negative\n",
       "5                  positive\n",
       "6                  positive\n",
       "7                  negative\n",
       "8                  negative\n",
       "9                  positive\n",
       "10                 negative\n",
       "11                 positive\n",
       "12                 negative"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the predicted model\n",
    "y_prediction=pd.DataFrame(y_pred)\n",
    "y_prediction.rename(columns={0:\"Sentiment_Classification\"},inplace=True)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the results of the sentiment in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment_Classification\n",
       "0                  positive\n",
       "1                  positive\n",
       "2                  negative\n",
       "3                  positive\n",
       "4                  negative\n",
       "5                  positive\n",
       "6                  positive\n",
       "7                  negative\n",
       "8                  negative\n",
       "9                  positive\n",
       "10                 negative\n",
       "11                 positive\n",
       "12                 negative"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the actual sentiment which was calculated using Vader\n",
    "y_testing=pd.DataFrame(y_test)\n",
    "y_testing.reset_index(inplace=True, drop=True)\n",
    "y_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the sentiments into a +1 value for positive and -1 value for negative to calculate model accuracy\n",
    "### Then convert the values columns to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction.loc[y_prediction['Sentiment_Classification']=='positive', 'value'] = 1\n",
    "y_prediction.loc[y_prediction['Sentiment_Classification']=='negative','value']= -1\n",
    "\n",
    "y_testing.loc[y_testing['Sentiment_Classification']=='positive', 'value'] = 1\n",
    "y_testing.loc[y_testing['Sentiment_Classification']=='negative','value']= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test= np.asanyarray(y_testing[['value']]) \n",
    "error_pred = np.asanyarray(y_prediction[['value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy:  0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model accuracy\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt \n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(error_test, error_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The trained model gives an accuracy of 84.6% on the test data\n",
    "### This means that it can be a good estimator of the sentiment in crude oil articles\n",
    "### However, the model could have the following drawbacks: The Vader library may be incapable of evaluating certain finance specific sentiments (for e.g. bullish, bearish). To solve this problem, a lot more emphasis needs to be put on the data collection. A possible way of obtaining data would be to send out surveys containing statements or phrases and asking finance professionals to give a score in a range of -5 to +5 (-5 being most negative and +5 being most positive). This data could then be used to develop the model and will definitely provide more accurate insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
